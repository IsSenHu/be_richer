# 快速开始

[TOC]

### [第一步: 下载](https://kafka.apache.org/quickstart#quickstart_download)

[下载](https://www.apache.org/dyn/closer.cgi?path=/kafka/2.4.0/kafka_2.12-2.4.0.tgz) the 2.4.0 release 并且解压它。

```bash
> wget http://mirror.bit.edu.cn/apache/kafka/2.4.0/kafka_2.12-2.4.0.tgz
> tar -xzf kafka_2.12-2.4.0.tgz
> cd kafka_2.12-2.4.0
```

### [第二步: 启动服务器](https://kafka.apache.org/quickstart#quickstart_startserver)

Kafka使用ZooKeeper，所以请先启动ZooKeeper服务器。 如果您还没有，您可以使用kafka随附的便利脚本来快速获取单节点ZooKeeper实例。

```bash
> bin/kafka-server-start.sh config/server.properties
```

### [第三步: 创建Topic](https://kafka.apache.org/quickstart#quickstart_createtopic)

让我们创建一个名字为"test"的，单分区的，一个副本的topic

```bash
> bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test
```

现在，如果我们运行list topic命令，便可以看到该主题

```bash
> bin/kafka-topics.sh --list --bootstrap-server localhost:9092
test
```

或者，除了手动创建主题外，还可以配置你的brokers为在发布不存在的主题时自动创建主题。

### [第四步: 发送一些消息](https://kafka.apache.org/quickstart#quickstart_send)

Kafka带有一个命令行客户端，它将从文件或标准输入中获取输入，并将其作为消息发送到Kafka集群。 默认情况下，每行将作为单独的消息发送。

运行生产者，然后在控制台中键入一些消息以发送到服务器。

```bash
> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
This is a message
This is another message
```

### [第五步: 启动一个消费者](https://kafka.apache.org/quickstart#quickstart_consume)

```bash
> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
This is a message
This is another message
```

如果上面的每个命令都在不同的终端上运行，那么您现在应该能够在生产者终端中键入消息，并看到它们出现在消费者终端中。

所有的命令行工具都有其他选项。 在不带参数的情况下运行该命令将显示更多详细的用法信息。

### [第六步: 设置多broker集群](https://kafka.apache.org/quickstart#quickstart_multibroker)

到目前为止，我们是在单broker上运行，但这并不有趣。对于Kafka来说，单个broker只是一个大小为1的集群，因此除了启动更多的代理实例之外，没有什么太大的变化。但是，只是为了感受一下，让我们将集群扩展到三个节点（仍然全部在本地计算机上）。

首先，我们为每个broker创建一个配置文件

```bash
> cp config/server.properties config/server-1.properties
> cp config/server.properties config/server-2.properties
```

现在编辑这些新文件并设置以下属性：

```text
config/server-1.properties:
    broker.id=1
    listeners=PLAINTEXT://:9093
    log.dirs=/tmp/kafka-logs-1
 
config/server-2.properties:
    broker.id=2
    listeners=PLAINTEXT://:9094
    log.dirs=/tmp/kafka-logs-2
```

`broker.id`是集群中每个节点的唯一且永久的名称。 我们只需要覆盖端口和日志目录，这是因为我们都在同一台计算机上运行它们，并且希望所有代理都不要试图在同一端口上注册或覆盖彼此的数据。

我们已经有Zookeeper并启动了单个节点，因此我们只需要启动两个新节点

```bash
> bin/kafka-server-start.sh config/server-1.properties &
> bin/kafka-server-start.sh config/server-2.properties &
```

现在为这3个复制因子创建一个新的topic

```bash
bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 3 --partitions 1 --topic my-replicated-topic
```

好的，但是现在有了集群，我们如何知道哪个broker在做什么？ 要查看请运行“describe topics”命令

```bash
bin/kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic my-replicated-topic
Topic:my-replicated-topic   PartitionCount:1    ReplicationFactor:3 Configs:
    Topic: my-replicated-topic  Partition: 0    Leader: 1   Replicas: 1,2,0 Isr: 1,2,0
```

这是输出的说明。 第一行给出了所有分区的摘要，每一行都给出了有关一个分区的信息。 由于该主题只有一个分区，因此只有一行。

- "Leader"是负责给定分区的所有读写操作。每个节点都是分区中随机选择的一部分的leader。
- “Replicas”是复制此分区的日志的节点列表，无论它们是主节点还是当前活动节点。
- “Isr”是“同步”副本的集合。这是副本列表的一个子集，它当前是活动的，并被提交给领导者。

注意，在我的示例中，节点1是topic的唯一分区的leader。

我们可以运行相同的命令，我们创建的test topic，看看它在哪里

```bash
> bin/kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic test
Topic:test  PartitionCount:1    ReplicationFactor:1 Configs:
    Topic: test Partition: 0    Leader: 0   Replicas: 0 Isr: 0
```

因此，这并不奇怪——原始主题没有副本，并且位于服务器0上，这是我们创建它时集群中惟一的服务器。

让我们发布一些消息到我们的新主题

```bash
> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic my-replicated-topic
my test message 1
my test message 2
```

现在让我们消费这些消息

```bash
> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic my-replicated-topic
my test message 1
my test message 2
```

现在让我们测试一下容错能力。broker1扮演了Leader的角色，所以让我们杀了它

```bash
> ps aux | grep server-1.properties
7564 ttys002    0:15.91 /System/Library/Frameworks/JavaVM.framework/Versions/1.8/Home/bin/java...
> kill -9 7564
```

领导已经切换到一个followers和节点1不再同步复制集

```bash
> bin/kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic my-replicated-topic
Topic:my-replicated-topic   PartitionCount:1    ReplicationFactor:3 Configs:
    Topic: my-replicated-topic  Partition: 0    Leader: 2   Replicas: 1,2,0 Isr: 2,0
```

但是这些信息仍然可以被消费，即使最初写这些消息的Leader已经不在了

```bash
> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic my-replicated-topic
my test message 1
my test message 2
```

### [第七步: 使用Kafka连接导入/导出数据](https://kafka.apache.org/quickstart#quickstart_kafkaconnect)

从控制台写入数据并将其写入控制台是一个方便的起点，但是您可能希望使用来自其他来源的数据或将数据从Kafka导出到其他系统。对于许多系统，您可以使用Kafka Connect来导入或导出数据，而不是编写定制的集成代码。

Kafka Connect是Kafka包含的一个工具，可以将数据导入和导出到Kafka。它是一个运行连接器的可扩展工具，连接器实现了与外部系统交互的自定义逻辑。在这个快速入门中，我们将看到如何使用简单的连接器运行Kafka Connect，这些连接器将数据从文件导入Kafka topic，并将数据从Kafka主题导出到文件。

首先，我们将创建一些种子数据来测试

```bash
> echo -e "foo\nbar" > test.txt
```

接下来，我们将启动两个以独立模式运行的连接器，这意味着它们运行在一个单独的、本地的、专用的进程中。我们提供了三个配置文件作为参数。第一种始终是Kafka连接进程的配置，包含常见的配置，比如要连接的Kafka代理和数据的序列化格式。其余的配置文件每个都指定要创建的连接器。这些文件包括惟一的连接器名称、要实例化的连接器类以及连接器所需的任何其他配置。

```bash
> bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties
```

这些示例配置文件,包括与Kafka，使用你早些时候开始的默认的本地集群配置，创建两个连接器：第一种是source connector从输入文件中读取行到每一个Kafka的Topic，第二个是sink connector读取消息从卡夫卡的话题和生产每一行的输出文件。

```bash
> more test.sink.txt
foo
bar
```

注意，数据被存储在Kafka Topic connect-test中，所以我们也可以运行控制台消费者来查看主题中的数据(或者使用自定义消费者代码来处理它)

```bash
> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning
{"schema":{"type":"string","optional":false},"payload":"foo"}
{"schema":{"type":"string","optional":false},"payload":"bar"}
```

连接器继续处理数据，所以我们可以将数据添加到文件中，并看到它通过管道移动

```bash
> echo Another line>> test.txt
```

您应该看到这一行出现在控制台消费者输出和接收器文件中。

### [第八步: 使用Kafka流来处理数据](https://kafka.apache.org/quickstart#quickstart_kafkastreams)

Kafka Streams是一个客户端库，用于构建关键任务的实时应用程序和微服务，其中的输入和/或输出数据存储在Kafka集群中。Kafka Streams结合了在客户端编写和部署标准Java和Scala应用程序的简单性，以及Kafka服务器端集群技术的优点，使这些应用程序具有高度可伸缩性、弹性、容错、分布式等特性。这个[quickstart example](https://kafka.apache.org/24/documentation/streams/quickstart) 将演示如何运行这个库中编写的流应用程序。